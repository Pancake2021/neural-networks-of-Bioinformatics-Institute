{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Выберите наборы весов и смещений, которые позволят изображенному многослойному перцептрону (в данном случае это сеть из \"перцептронов\" в понимании предыдущей недели) решать проблему XOR. XOR — логическая функция от двух переменных (которые будут подаваться на входы перцептрону) со следующей таблицей истинности: \n",
    "\n",
    " \n",
    "У сети, изображённой ниже, все нейроны внутреннего и выходного слоя — это обычные перцептроны, у которых пронумерованы веса (цифры на стрелочках) и смещения (цифры в кружках, соответствующих этим перцептронам). На входном слое — просто входы, всё как обычно. \n",
    "\n",
    "\n",
    "\n",
    "Ваша задача — написать в обозначенном нумерацией порядке через запятую числа (с десятичным разделителем-точкой), которые, на ваш взгляд, нужно поместить в соответствующий вес или смещение, чтобы получившаяся сеть, принимая на вход нули и единицы, отдавала на выходе значение XOR для поданных входов.\n",
    "\n",
    "Пример. Вы считаете, что сеть должна иметь вот такой вид:\n",
    "\n",
    "Тогда вы пишете в ответ: -4.0, 4.0, 5.0, -1.0, 0.0, 1.0, 4.0, 3.0, 5.0. Мы посчитаем, что выдаёт сетка на ваших весах, и узнаем, правы ли вы.\n",
    "Подсказка. Мы знаем, что перцептроны-одиночки умеют имитировать поведение простых логических функций вроде AND, OR, NOT. Структура этой сети — два перцептрона от входных данных и ещё один перцептрон от значений первых двух перцептронов. "
   ],
   "id": "edbf25d68c5caadc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 2,
   "source": "import numpy as np #Analysis of the algorithm for reverse distribution",
   "id": "initial_id"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T10:49:18.542422Z",
     "start_time": "2024-08-23T10:49:18.531546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, w, b):\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        \n",
    "    def forward_pass(self, single_input):\n",
    "        result = 0\n",
    "        for i in range(0, len(self.w)):\n",
    "            result += self.w[i] * single_input[i]\n",
    "        result += self.b\n",
    "\n",
    "        if result > 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def train_on_single_example(self, example, y):\n",
    "#         out = int(self.w.T.dot(example) + self.b > 0) # в матричном виде, без self.forward_pass\n",
    "        out = self.forward_pass(example)\n",
    "        error = y - out\n",
    "        self.w = self.w + error * example\n",
    "        self.b = self.b + error\n",
    "        return error\n",
    "    \n",
    "    def train_until_convergence(self, input_matrix, y, max_steps=1e8):\n",
    "        i = 0\n",
    "        errors = 1\n",
    "        while errors and i < max_steps:\n",
    "            i += 1\n",
    "            errors = 0\n",
    "            for example, answer in zip(input_matrix, y):\n",
    "                example = example.reshape((example.size, 1))\n",
    "                error = self.train_on_single_example(example, answer)\n",
    "                errors += 0 if error == 0 else 1  # ЗДЕСЬ БЫЛА ОШИБКА"
   ],
   "id": "5ea2c4788030ea8e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T10:49:22.145642Z",
     "start_time": "2024-08-23T10:49:22.139698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "w = np.array([[0,0]]).T\n",
    "p1 = Perceptron(w.copy(), 0) # a1 = AND(not(a),b)\n",
    "p2 = Perceptron(w.copy(), 0) # a2 = AND(a, not(b))\n",
    "p3 = Perceptron(w.copy(), 0) # OR(a1, a2)\n",
    "X = np.array([[0, 0], [1, 0], [0, 1], [1, 1]])\n",
    "y1 = np.array([[0, 0, 1, 0]]).T\n",
    "y2 = np.array([[0, 1, 0, 0]]).T\n",
    "y3 = np.array([[0, 1, 1, 1]]).T\n",
    "p1.train_until_convergence(X, y1)\n",
    "p2.train_until_convergence(X, y2)\n",
    "p3.train_until_convergence(X, y3)\n",
    "print(p1.w, p1.b)\n",
    "print(p2.w, p2.b)\n",
    "print(p3.w, p3.b)\n",
    "\n",
    "for example in X:\n",
    "    print(example)\n",
    "    a = p1.forward_pass(example)\n",
    "    b = p2.forward_pass(example)\n",
    "    print(p3.forward_pass([a, b]))"
   ],
   "id": "6943a7f954d4496a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2]\n",
      " [ 1]] [0]\n",
      "[[ 1]\n",
      " [-1]] [0]\n",
      "[[1]\n",
      " [1]] [0]\n",
      "[0 0]\n",
      "0\n",
      "[1 0]\n",
      "1\n",
      "[0 1]\n",
      "1\n",
      "[1 1]\n",
      "0\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "как было предложено ниже:\n",
    "xor=or(and(!a,b),and(a,!b))\n",
    "для  and(!a,b):\n",
    "a | b | !a | and(!a,b)\n",
    "-------------------------\n",
    "0 | 0 | 1 | 0\n",
    "0 | 1 | 1 | 1\n",
    "1 | 0 | 0 | 0\n",
    "1 | 1 | 0 | 0\n",
    "Напишем систему уравнений (x1*w1+x2*w2+b ...):\n",
    "0*w1+0*w2+b<=0\n",
    "0*w1+1*w2+b>0\n",
    "1*w1+0*w2+b<=0\n",
    "1*w1+1*w2+b<=0\n",
    "\n",
    "получаем:\n",
    "b<=0\n",
    "w2+b>0\n",
    "w1+b<=0\n",
    "w1+w2+b<=0\n",
    "\n",
    "Решаем подбором, результат записываем в ответ: w1,w2,b\n",
    "Подобны образом составляем таблицу и систему уравнений для and(a,!b), результат записываем (продолжаем) в ответ: ...,w1,w2,b\n",
    "И, наконец, составляем таблицу и систему уравнений для or(...), результат записываем (продолжаем) в ответ: ...,w1,w2,b\n"
   ],
   "id": "dfaaadd6d05f3f3a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T11:20:51.806884Z",
     "start_time": "2024-08-23T11:20:51.782692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(2, activation=tf.math.sigmoid),\n",
    "    keras.layers.Dense(1, activation=tf.math.sigmoid)\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.train.GradientDescentOptimizer(1), \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x, y, epochs=5000)\n",
    "\n",
    "print(model.get_weights())"
   ],
   "id": "d955e3270629469c",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.train' has no attribute 'GradientDescentOptimizer'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 16\u001B[0m\n\u001B[1;32m      8\u001B[0m y \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([[\u001B[38;5;241m0\u001B[39m], [\u001B[38;5;241m1\u001B[39m], [\u001B[38;5;241m1\u001B[39m], [\u001B[38;5;241m0\u001B[39m]])\n\u001B[1;32m     10\u001B[0m model \u001B[38;5;241m=\u001B[39m keras\u001B[38;5;241m.\u001B[39mSequential([\n\u001B[1;32m     11\u001B[0m     keras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mDense(\u001B[38;5;241m2\u001B[39m, activation\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mmath\u001B[38;5;241m.\u001B[39msigmoid),\n\u001B[1;32m     12\u001B[0m     keras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mDense(\u001B[38;5;241m1\u001B[39m, activation\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mmath\u001B[38;5;241m.\u001B[39msigmoid)\n\u001B[1;32m     13\u001B[0m ])\n\u001B[0;32m---> 16\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mtrain\u001B[38;5;241m.\u001B[39mGradientDescentOptimizer(\u001B[38;5;241m1\u001B[39m), \n\u001B[1;32m     17\u001B[0m               loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbinary_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     18\u001B[0m               metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     20\u001B[0m model\u001B[38;5;241m.\u001B[39mfit(x, y, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5000\u001B[39m)\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28mprint\u001B[39m(model\u001B[38;5;241m.\u001B[39mget_weights())\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'tensorflow._api.v2.train' has no attribute 'GradientDescentOptimizer'"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
